Raw Kubernetes Install:

swapoff -a & uncomment the line for swap on /etc/fstab
setenforce 0
yum install -y kubelet kubeadm kubectl
systemctl enable kubelet
systemctl start kubelet
kubeadm init --pod-network-cidr=10.224.0.0/16
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
kuberctl get nodes



In this hands-on lesson, we'll go through everything you need to install Kubernetes on a bare CentOS system.

Here are the commands I copy/pasted in during the video:

cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF

cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.9.1/Documentation/kube-flannel.yml

XXXXXXX
------------------------
Exercise: Deploying Your Cluster
Exercise Instructions
Solution
Mark as Completed

Update: For users experiencing the hang on the initialization, we've tracked down the issue and updated the instructions accordingly.

These instructions will help you deploy a fully working Kubernetes Cluster on Linux Academy Cloud Servers.

First, create a master server using the "Cloudnative Kubernetes" engine.  Once this machine has booted, log in to it, change the password, and then start the deployment.

Make sure that the instance has the latest packages installed.

sudo apt-get update

The kubeadm tool attempts to simultaneously download all the images for the control pods, which overwhelms our lab server. We will pull the images first, so kubeadm can build the containers more efficiently:

sudo docker pull k8s.gcr.io/kube-scheduler-amd64:v1.10.1
sudo docker pull k8s.gcr.io/etcd-amd64:3.1.12
sudo docker pull  k8s.gcr.io/kube-apiserver-amd64:v1.10.1
sudo docker pull k8s.gcr.io/kube-controller-manager-amd64:v1.10.1

Note that the version numbers might change and the "latest" tag won't work. We'll update this document as soon as we notice a change.

K8s requires a pod network to function. We are going to use Flannel, so we need to pass in a flag to the deployment script so K8s knows how to configure itself:

sudo kubeadm init --pod-network-cidr=10.244.0.0/16

This command might take a fair amount of time to complete, possibly as much as ten minutes. Once it's complete, make note of the join command output by kubeadm init that looks like this:

kubeadm join --token --discovery-token-ca-cert-hash sha256:

You will run that command on the other nodes to allow them to join the cluster -- but not quite yet.  We'll get to that soon.

Create a directory:

mkdir -p $HOME/.kube

Next, you'll move the configuration files to a location usable by your local user. if you copy and paste these commands, do so one at a time, or your sudo password prompt might cause things to go slightly wrong and you might have to redo it.

sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config 

sudo chown $(id -u):$(id -g) $HOME/.kube/config

In order for your pods to communicate with one another, you'll need to install pod networking.  We are going to use Flannel for our Container Network Interface (CNI) because it's easy to install and reliable.  Enter this command:

kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

Author's Note: This link has changed since the course's original release. The old link no longer works. Please use this one to install the Flannel CNI.

Next, you'll check to make sure everything is coming up properly.

kubectl get pods --all-namespaces

Once the kube-dns-xxxx containers are up, your cluster is ready to accept worker nodes.  Create three or so worker nodes the same way you created your master nodes -- by bringing up the "Cloudnative Kubernetes" image on your Cloud Servers tab above.

ssh to each of the other nodes in the cluster, and execute the kubeadm join command you noted earlier.  You will need execute this command with root privileges, so be sure to add "sudo" to the beginning of the command in order for it to complete correctly.  Once this command is issued, you may log out of the node.  Kubernetes will configure it for you from this point on.

See the video "Setting Up Your Cluster" in this course for details and a full walkthrough of the process.

On the master, you can watch the node come up by repeatedly running:

kubtctl get nodes

----------------------


Exercise: Run a Job
Exercise Instructions
Solution
Mark as Completed

1. The full command is kubectl describe job pi

2. The previous command will give you the name of the pod associated with the job, which you will need to pass into the kubectl logs command.

For example: (the precise code will vary)

 

$ kubectl describe job pi
Name:           pi
Namespace:      default
Selector:       controller-uid=7ffe0296-f7ad-11e7-8717-0abccbe536d6
Labels:         controller-uid=7ffe0296-f7ad-11e7-8717-0abccbe536d6
                job-name=pi
Annotations:    
Parallelism:    1
Completions:    1
Start Time:     Fri, 13 Apr 2018 15:30:20 +0000
Pods Statuses:  0 Running / 1 Succeeded / 0 Failed
Pod Template:
  Labels:  controller-uid=7ffe0296-f7ad-11e7-8717-0abccbe536d6
           job-name=pi
  Containers:
   pi:
    Image:  perl
    Port:   
    Command:
      perl
      -Mbignum=bpi
      -wle
      print bpi(2000)
    Environment:  
    Mounts:       
  Volumes:        
Events:
  Type    Reason            Age   From            Message
  ----    ------            ----  ----            -------
  Normal  SuccessfulCreate  4m    job-controller  Created pod: pi-fmctx

$ kubectl logs pi-fmctx

3. The yaml could vary in a couple of ways, but here is an example solution:

apiVersion: batch/v1
kind: Job
metadata:
  name: busybox
spec:
  template:
    spec:
      containers:
      - name: busybox
        image: busybox
        command: ["sleep", "10"]
      restartPolicy: Never
  backoffLimit: 4

---------------------------------

Exercise: Deploy a Pod
Exercise Instructions
Solution
Mark as Completed

1. This pod will cause the alpine linux container to sleep for 3600 seconds (1 hour) and then exit. Kubernetes will then restart the pod.

2. If the yaml is named alpine.yaml then the command is kubectl create -f alpine.yaml

3. There are a few ways to accomplish this.

    Use the file method: kubectl delete -f alpine.yaml
    Use the object method: kubectl delete pod alpine or kubectl delete pod/alpine

4. There are many possibilities, but here is yaml that satisfies the exercise:

apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
spec:
  containers:
  -  name: nginx
      image: nginx
  restartPolicy: Always

5. Depending on the file name, the command might be: kubectl create -f nginx-pod.yaml
-----------------------------


Exercise: Explore the Sandbox
Exercise Instructions
Solution
Mark as Completed

1. The command kubectl get nodes will give the current status of all nodes.

2. You can get this information in a variety of ways:

    kubectl describe node node-name
    kubectl get pods --all-namespaces -o wide will list all pods and which nodes they are currently running on.

3. kubectl describe node node-2-name will list DiskPressure and MemoryPressure statuses so you can see how it is doing.

4. kubectl get pods -n kube-system will provide the desired results.
----------------------------------------------------------------------
